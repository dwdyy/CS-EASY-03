## C语言内存模型

> 什么是“栈溢出”？

在函数调用时，在函数定义的局部变量,数组,结构体，函数信息都会储存在栈中,当函数结束时而释放，因此递归访问，局部变量定义会导致栈无法释放或覆盖，出现栈溢出

如在以下代码中因无限递归发生了栈溢出

```c
int getx(int x){
    return getx(x-1);
}
int main(){
    getx(1);
}
// Segmentation fault 因栈溢出发生程序越界
```

> 堆区和栈区的区别是什么？

- 堆区存放的是程序员手动申请和释放的空间

​		而栈区存放在函数定义的局部变量,数组,结构体,函数信息等

- 堆区更大也更慢，栈区小但快
- 栈区以栈来实现，而堆区由程序自动分配内存

>  程序运行过程中，内存模型当中的哪些区是只读的，哪些区是可读写的？

- 程序代码区,常量区,动态链接库 只读
- 全局数据区 堆区 栈区  可读写

> 如何使用malloc()、free()函数，它们针对的哪一个区进行操作？

 ```
 int *a = (int*)malloc(N * sizeof(int));
 free(a)
 ```

在这里 $malloc$ 返回申请内存块的指针(void*)类型，将它转化为 $int*$ 类型来使用

 $ N * sizeof(int)$ 是内存块大小

 $free$ 是释放分配内存

> 为什么要对程序使用的内存进行管理？

- 如果程序可以随意访问内存，会导致安全问题
- 及时回收内存，避免内存泄漏
- 可以更有效利用内存，比如如果随意使用，可能出现相邻使用内存之间存在大量内存没有使用

## 内存模型的应用

```c
#include <stdio.h>
#include <stdlib.h>

const int constValue = 100;
const char* constString = "Hello, World!";
int globalVar = 10;

void function(int arg) {
    int localVar = 20;
    int *ptr = malloc(sizeof(int));
    *ptr = 30;
    free(ptr);
}

int main() {
    static int staticVar = 40;
    int localVarMain = 50;
    function(60);
    return 0;
}
```

- `constValue` 常量区 

- `constString ` 常量区

​	这两个变量都被 $const$ 修饰，表明其是固定值，在编译时就已经确定

- `globalVar ` 全局数据区

​	该变量定义为全局变量 且未被 $const$ 修饰

- `staticVar` 全局数据区

​	尽管该变量定义在函数内，只能被该函数使用,但其被 $static$ 修饰，表示其	为**静态全局变量**，储存在全局数据区，不会因为函数结束而释放

- `localVar` `localVarMain` 栈区
其为 $function/main$ 函数的局部变量，放在栈区

- `ptr `

  其申请的空间在堆区，但其本身在栈区

## 浅谈Cache

> 什么是冯诺伊曼体系结构？什么是现代计算机的组织结构？这两者的不同点在哪里？

冯.诺依曼体系由五大构件组成

![Von_Neumann_Architecture.svg](image\Von_Neumann_Architecture.png)

- 运算器:进行算数运算与逻辑运算
- 控制器：读取指令并控制运算器运算
- 存储器:存放欲的程序和数据
- 输入设备
- 输出设备

现代计算机的组织结构

![v2-15c7328be8415b48684a1bc5972daff3_1440w](image\v2-15c7328be8415b48684a1bc5972daff3.webp)

不同点

- 现代指令与数据是分开的
- 现代引入缓存，减少对内存的读写

- 现代运算器与控制器合并为cpu

> 主存储器是如何工作的？

​	程序需要读取数据 -> cpu计算出内存地址 -> 传递给内存控制器 ->内存地址器前后发送行列地址到DRAM芯片 -> 传递给内存控制器 ->储存到寄存器中

> 什么是Cache的局部性原理？它包括哪些方面的内容？

- 时间局部，如果某个数据被访问，那么未来极大可能会再次访问
- 空间局部，如果某个数据被访问，那么未来它周围的数据也可能再次访问

> Cache的运用为什么可以加快系统整体性能

首先Cache位于CPU旁边，用SRAM构建，容量小，延迟低，比直接访问内存速度更快，

利用局部性原理，命中率高,加快数据获取，减少cpu等待时间，更快返回结果

## 代码优化

下面代码是一段普通的矩阵乘法，以下在我们不加优化下编译运行

```
    for(int i=1;i<=M;i++)
    for(int j=1;j<=M;j++)
    for(int k=1;k<=M;k++)
    c[i][j] += a[i][k] * b[k][j];
```

我们知道二维数组中每一行的地址是连续的

上述代码在枚举k的时候，对于连续的a数组很容易缓存命中

然而我们每一次跳b数组，因为地址不连续且大幅度变化，会导致缓存几乎无法命中

因此我们可以交换枚举顺序

```
    for(int i=1;i<=M;i++)
    for(int k=1;k<=M;k++)
    for(int j=1;j<=M;j++)
    c[i][j] += a[i][k] * b[k][j];
```

这样在枚举j的时候，a数组需要的地址没有变化，b数组访问地址连续了，缓存命中率就大大提高了

下面是不同枚举顺序的运行时间

```
8.153997 7.794327 8.217228 ijk
6.580054 6.719174 6.724004 kij
6.440610 6.458934 6.450547 ikj
```

有趣的是，我们发现 `ikj` 比` kij`还要快一点

因为 `kij` 中在枚举k时 `a[i][k]` 并不连续

而 `ikj` `a[i][k]` 是连续的 有进一步提高了缓存的效率(虽然很小)

[Code](a.c)
